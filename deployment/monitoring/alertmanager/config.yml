# Production Alertmanager Configuration for Horme POV
# Multi-channel alert routing and escalation

global:
  # SMTP configuration for email alerts
  smtp_smarthost: '${SMTP_HOST}:${SMTP_PORT}'
  smtp_from: 'alerts@horme.ai'
  smtp_auth_username: '${SMTP_USERNAME}'
  smtp_auth_password: '${SMTP_PASSWORD}'
  smtp_require_tls: true
  
  # Slack configuration
  slack_api_url: '${SLACK_WEBHOOK_URL}'
  
  # Default timeout for alerts
  resolve_timeout: 5m

# Templates for custom notifications
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Route configuration - determines where alerts go
route:
  # Default settings for all alerts
  group_by: ['alertname', 'cluster', 'service']
  group_wait: 10s
  group_interval: 10s
  repeat_interval: 12h
  receiver: 'web.hook'
  
  # Routing tree
  routes:
    # Critical alerts - immediate notification
    - match:
        severity: critical
      receiver: 'critical-alerts'
      group_wait: 0s
      group_interval: 5m
      repeat_interval: 5m
      continue: true
      routes:
        # Database critical alerts
        - match:
            service: postgres
        - match:
            service: neo4j
        - match:
            service: redis
          receiver: 'database-critical'
        
        # Application critical alerts
        - match:
            service: horme-app
          receiver: 'application-critical'
        
        # Security critical alerts
        - match:
            team: security
          receiver: 'security-critical'
          group_wait: 0s
          repeat_interval: 1m

    # Warning alerts - standard notification
    - match:
        severity: warning
      receiver: 'warning-alerts'
      group_wait: 5m
      group_interval: 10m
      repeat_interval: 1h
      routes:
        # Performance warnings
        - match_re:
            alertname: '.*High.*Usage'
          receiver: 'performance-warnings'
        
        # Database warnings
        - match:
            team: data
          receiver: 'database-warnings'
        
        # ML/AI service warnings
        - match:
            team: ml
          receiver: 'ml-warnings'

    # Infrastructure alerts
    - match:
        team: platform
      receiver: 'platform-alerts'
      group_interval: 5m
      routes:
        # Monitoring infrastructure issues
        - match_re:
            service: 'prometheus|grafana|alertmanager'
          receiver: 'monitoring-alerts'

    # Backup and maintenance alerts
    - match:
        service: backup
      receiver: 'backup-alerts'
      group_interval: 30m
      repeat_interval: 6h

    # Development/testing alerts (lower priority)
    - match:
        environment: development
      receiver: 'dev-alerts'
      group_interval: 30m
      repeat_interval: 24h

# Inhibition rules - suppress certain alerts when others are firing
inhibit_rules:
  # Inhibit any warning if the same alert is critical
  - source_match:
      severity: 'critical'
    target_match:
      severity: 'warning'
    equal: ['alertname', 'instance']

  # If the entire app is down, don't alert on individual components
  - source_match:
      alertname: 'HormeAppDown'
    target_match_re:
      alertname: '.*'
    equal: ['instance']

  # If database is down, don't alert on high connections
  - source_match:
      alertname: 'PostgresPrimaryDown'
    target_match:
      alertname: 'PostgresHighConnections'
    equal: ['instance']

# Receiver configurations
receivers:
  # Default webhook receiver
  - name: 'web.hook'
    webhook_configs:
      - url: 'http://webhook-service:5000/alerts'
        send_resolved: true
        http_config:
          bearer_token: '${WEBHOOK_TOKEN}'

  # Critical alerts - multiple channels
  - name: 'critical-alerts'
    email_configs:
      - to: 'oncall@horme.ai'
        subject: 'üö® CRITICAL: {{ .GroupLabels.alertname }} - {{ .GroupLabels.instance }}'
        body: |
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          Severity: {{ .Labels.severity }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          
          {{ if .Annotations.runbook_url }}
          Runbook: {{ .Annotations.runbook_url }}
          {{ end }}
          {{ end }}
        headers:
          Subject: 'üö® CRITICAL ALERT: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - channel: '#alerts-critical'
        title: 'üö® Critical Alert'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Instance:* {{ .Labels.instance }}
          *Severity:* {{ .Labels.severity }}
          {{ if .Annotations.runbook_url }}
          *Runbook:* {{ .Annotations.runbook_url }}
          {{ end }}
          {{ end }}
        send_resolved: true
        color: 'danger'
    
    pagerduty_configs:
      - routing_key: '${PAGERDUTY_INTEGRATION_KEY}'
        description: '{{ .GroupLabels.alertname }} - {{ .GroupLabels.instance }}'
        severity: 'critical'
        details:
          summary: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'
          description: '{{ range .Alerts }}{{ .Annotations.description }}{{ end }}'
          runbook_url: '{{ range .Alerts }}{{ .Annotations.runbook_url }}{{ end }}'

  # Database critical alerts
  - name: 'database-critical'
    email_configs:
      - to: 'dba@horme.ai,oncall@horme.ai'
        subject: 'üóÑÔ∏è DATABASE CRITICAL: {{ .GroupLabels.alertname }}'
        body: |
          CRITICAL DATABASE ALERT
          
          {{ range .Alerts }}
          Service: {{ .Labels.service }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
    
    slack_configs:
      - channel: '#database-alerts'
        title: 'üóÑÔ∏è Critical Database Alert'
        text: |
          {{ range .Alerts }}
          *Service:* {{ .Labels.service }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Instance:* {{ .Labels.instance }}
          {{ end }}
        color: 'danger'

  # Application critical alerts
  - name: 'application-critical'
    email_configs:
      - to: 'dev-team@horme.ai,oncall@horme.ai'
        subject: 'üöÄ APPLICATION CRITICAL: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - channel: '#app-alerts'
        title: 'üöÄ Critical Application Alert'
        color: 'danger'

  # Security critical alerts
  - name: 'security-critical'
    email_configs:
      - to: 'security@horme.ai,ciso@horme.ai'
        subject: 'üîí SECURITY CRITICAL: {{ .GroupLabels.alertname }}'
        body: |
          CRITICAL SECURITY ALERT - IMMEDIATE ATTENTION REQUIRED
          
          {{ range .Alerts }}
          Alert: {{ .Annotations.summary }}
          Description: {{ .Annotations.description }}
          Instance: {{ .Labels.instance }}
          Time: {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
          
          This alert requires immediate investigation.
    
    slack_configs:
      - channel: '#security-alerts'
        title: 'üîí CRITICAL SECURITY ALERT'
        text: |
          {{ range .Alerts }}
          ‚ö†Ô∏è **SECURITY INCIDENT DETECTED** ‚ö†Ô∏è
          
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Instance:* {{ .Labels.instance }}
          *Time:* {{ .StartsAt.Format "2006-01-02 15:04:05" }}
          {{ end }}
        color: 'danger'

  # Warning alerts
  - name: 'warning-alerts'
    email_configs:
      - to: 'devops@horme.ai'
        subject: '‚ö†Ô∏è WARNING: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - channel: '#alerts-warning'
        title: '‚ö†Ô∏è Warning Alert'
        color: 'warning'

  # Performance warnings
  - name: 'performance-warnings'
    slack_configs:
      - channel: '#performance-alerts'
        title: 'üìä Performance Warning'
        text: |
          {{ range .Alerts }}
          *Alert:* {{ .Annotations.summary }}
          *Description:* {{ .Annotations.description }}
          *Instance:* {{ .Labels.instance }}
          {{ end }}
        color: 'warning'

  # Database warnings
  - name: 'database-warnings'
    slack_configs:
      - channel: '#database-alerts'
        title: 'üóÑÔ∏è Database Warning'
        color: 'warning'

  # ML/AI warnings
  - name: 'ml-warnings'
    slack_configs:
      - channel: '#ml-alerts'
        title: 'ü§ñ ML Service Warning'
        color: 'warning'

  # Platform alerts
  - name: 'platform-alerts'
    slack_configs:
      - channel: '#platform-alerts'
        title: 'üèóÔ∏è Platform Alert'
        color: 'warning'

  # Monitoring alerts
  - name: 'monitoring-alerts'
    email_configs:
      - to: 'sre@horme.ai'
        subject: 'üìä MONITORING: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - channel: '#monitoring-alerts'
        title: 'üìä Monitoring Alert'
        color: 'warning'

  # Backup alerts
  - name: 'backup-alerts'
    email_configs:
      - to: 'backup-admin@horme.ai'
        subject: 'üíæ BACKUP: {{ .GroupLabels.alertname }}'
    
    slack_configs:
      - channel: '#backup-alerts'
        title: 'üíæ Backup Alert'
        color: 'warning'

  # Development alerts (low priority)
  - name: 'dev-alerts'
    slack_configs:
      - channel: '#dev-alerts'
        title: 'üîß Development Alert'
        color: 'good'

# Time intervals for different severity levels
time_intervals:
  - name: weekdays-business-hours
    time_intervals:
      - times:
          - start_time: '09:00'
            end_time: '17:00'
        weekdays: ['monday:friday']
        location: 'America/New_York'

  - name: weekends
    time_intervals:
      - weekdays: ['saturday', 'sunday']

  - name: nights
    time_intervals:
      - times:
          - start_time: '17:01'
            end_time: '08:59'
        weekdays: ['monday:friday']