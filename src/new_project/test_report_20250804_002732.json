{
  "start_time": "2025-08-04T00:26:08.477450",
  "total_duration": 83.904743,
  "tiers_run": 3,
  "tiers_passed": 1,
  "tiers_failed": 2,
  "tiers_skipped": 0,
  "failed_tiers": [
    "performance",
    "compliance"
  ],
  "docker_services": {
    "docker": false,
    "postgres": false,
    "neo4j": false,
    "chromadb": false,
    "redis": false
  },
  "overall_success": false,
  "results": {
    "unit": {
      "tier": "unit",
      "success": true,
      "return_code": 0,
      "duration": 26.144239,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.9, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.9', 'Platform': 'Windows-10-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.5.3', 'asyncio': '1.1.0', 'cov': '6.2.1', 'forked': '1.6.0', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'split': '0.10.0', 'timeout': '2.4.0', 'xdist': '3.8.0'}}\nrootdir: C:\\Users\\fujif\\OneDrive\\Documents\\GitHub\\horme-pov\\src\\new_project\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.5.3, asyncio-1.1.0, cov-6.2.1, forked-1.6.0, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, split-0.10.0, timeout-2.4.0, xdist-3.8.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ntimeout: 1.0s\ntimeout method: thread\ntimeout func_only: False\ncollecting ... collected 522 items / 513 deselected / 9 selected\n\ntests/unit/test_api_client_unit.py::TestAPIClientPerformance::test_initialization_performance PASSED [ 11%]\ntests/unit/test_api_client_unit.py::TestAPIClientPerformance::test_token_operations_performance PASSED [ 22%]\ntests/unit/test_api_client_unit.py::TestAPIClientPerformance::test_parameter_validation_performance PASSED [ 33%]\ntests/unit/test_foundation_working.py::TestMockingCapabilities::test_simple_mock PASSED [ 44%]\ntests/unit/test_foundation_working.py::TestMockingCapabilities::test_patch_decorator PASSED [ 55%]\ntests/unit/test_foundation_working.py::TestMockingCapabilities::test_mock_api_call PASSED [ 66%]\ntests/unit/test_foundation_working.py::TestFoundationComplete::test_complete_foundation_workflow PASSED [ 77%]\ntests/unit/test_test_infrastructure.py::TestPerformanceRequirements::test_unit_test_execution_time PASSED [ 88%]\ntests/unit/test_test_infrastructure.py::TestPerformanceRequirements::test_data_generation_performance PASSED [100%]\n\n- generated xml file: C:\\Users\\fujif\\OneDrive\\Documents\\GitHub\\horme-pov\\src\\new_project\\test-results-unit.xml -\n=============================== tests coverage ================================\n_______________ coverage: platform win32, python 3.11.9-final-0 _______________\n\nCoverage HTML written to dir htmlcov\nCoverage XML written to file coverage.xml\n===================== 9 passed, 513 deselected in 23.02s ======================\n",
      "stderr": "C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\coverage\\report_core.py:110: CoverageWarning: Couldn't parse Python file 'C:\\Users\\fujif\\OneDrive\\Documents\\GitHub\\horme-pov\\src\\new_project\\fix_sdk_imports.py' (couldnt-parse)\n  coverage._warn(msg, slug=\"couldnt-parse\")\n<unknown>:58: DeprecationWarning: invalid escape sequence '\\!'\nC:\\Users\\fujif\\OneDrive\\Documents\\GitHub\\horme-pov\\src\\new_project\\run_complete_tests.py:58: DeprecationWarning: invalid escape sequence '\\!'\n  print('ALL TEST SUITES PASSED\\!')\n<unknown>:58: DeprecationWarning: invalid escape sequence '\\!'\nC:\\Users\\fujif\\OneDrive\\Documents\\GitHub\\horme-pov\\src\\new_project\\run_complete_tests.py:58: DeprecationWarning: invalid escape sequence '\\!'\n  print('ALL TEST SUITES PASSED\\!')\n<unknown>:58: DeprecationWarning: invalid escape sequence '\\!'\n<unknown>:58: DeprecationWarning: invalid escape sequence '\\!'\n<unknown>:58: DeprecationWarning: invalid escape sequence '\\!'\nC:\\Users\\fujif\\OneDrive\\Documents\\GitHub\\horme-pov\\src\\new_project\\run_complete_tests.py:58: DeprecationWarning: invalid escape sequence '\\!'\n  print('ALL TEST SUITES PASSED\\!')\n",
      "command": "C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pytest tests/unit/ -v --tb=short --timeout=1 --junit-xml=test-results-unit.xml -m unit --cov=. --cov-report=html --cov-report=xml",
      "timeout_limit": 1,
      "max_duration": 300.0
    },
    "performance": {
      "tier": "performance",
      "success": false,
      "return_code": 1,
      "duration": 49.83596,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.9, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.9', 'Platform': 'Windows-10-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.5.3', 'asyncio': '1.1.0', 'cov': '6.2.1', 'forked': '1.6.0', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'split': '0.10.0', 'timeout': '2.4.0', 'xdist': '3.8.0'}}\nrootdir: C:\\Users\\fujif\\OneDrive\\Documents\\GitHub\\horme-pov\\src\\new_project\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.5.3, asyncio-1.1.0, cov-6.2.1, forked-1.6.0, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, split-0.10.0, timeout-2.4.0, xdist-3.8.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ntimeout: 30.0s\ntimeout method: thread\ntimeout func_only: False\ncollecting ... collected 12 items\n\ntests/performance/test_performance_benchmarks.py::TestResponseTimeValidation::test_product_search_performance PASSED [  8%]\ntests/performance/test_performance_benchmarks.py::TestResponseTimeValidation::test_recommendation_performance PASSED [ 16%]\ntests/performance/test_performance_benchmarks.py::TestResponseTimeValidation::test_safety_validation_performance PASSED [ 25%]\ntests/performance/test_performance_benchmarks.py::TestResponseTimeValidation::test_vector_similarity_performance PASSED [ 33%]\ntests/performance/test_performance_benchmarks.py::TestThroughputAndConcurrency::test_concurrent_search_throughput PASSED [ 41%]\ntests/performance/test_performance_benchmarks.py::TestThroughputAndConcurrency::test_sustained_load_performance +++++++++++++++++++++++++++++++++++ Timeout +++++++++++++++++++++++++++++++++++\n~~~~~~~~~~~~~~~~~~~~~~~~~ Stack of MainThread (29380) ~~~~~~~~~~~~~~~~~~~~~~~~~\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytest\\__main__.py\", line 9, in <module>\n    raise SystemExit(pytest.console_main())\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\config\\__init__.py\", line 201, in console_main\n    code = main()\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\config\\__init__.py\", line 175, in main\n    ret: ExitCode | int = config.hook.pytest_cmdline_main(config=config)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_hooks.py\", line 512, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_manager.py\", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_callers.py\", line 121, in _multicall\n    res = hook_impl.function(*args)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\main.py\", line 336, in pytest_cmdline_main\n    return wrap_session(config, _main)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\main.py\", line 289, in wrap_session\n    session.exitstatus = doit(config, session) or 0\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\main.py\", line 343, in _main\n    config.hook.pytest_runtestloop(session=session)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_hooks.py\", line 512, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_manager.py\", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_callers.py\", line 121, in _multicall\n    res = hook_impl.function(*args)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\main.py\", line 367, in pytest_runtestloop\n    item.config.hook.pytest_runtest_protocol(item=item, nextitem=nextitem)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_hooks.py\", line 512, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_manager.py\", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_callers.py\", line 121, in _multicall\n    res = hook_impl.function(*args)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\runner.py\", line 117, in pytest_runtest_protocol\n    runtestprotocol(item, nextitem=nextitem)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\runner.py\", line 136, in runtestprotocol\n    reports.append(call_and_report(item, \"call\", log))\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\runner.py\", line 245, in call_and_report\n    call = CallInfo.from_call(\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\runner.py\", line 344, in from_call\n    result: TResult | None = func()\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\runner.py\", line 246, in <lambda>\n    lambda: runtest_hook(item=item, **kwds), when=when, reraise=reraise\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_hooks.py\", line 512, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_manager.py\", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_callers.py\", line 121, in _multicall\n    res = hook_impl.function(*args)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\runner.py\", line 178, in pytest_runtest_call\n    item.runtest()\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytest_asyncio\\plugin.py\", line 426, in runtest\n    super().runtest()\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\python.py\", line 1671, in runtest\n    self.ihook.pytest_pyfunc_call(pyfuncitem=self)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_hooks.py\", line 512, in __call__\n    return self._hookexec(self.name, self._hookimpls.copy(), kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_manager.py\", line 120, in _hookexec\n    return self._inner_hookexec(hook_name, methods, kwargs, firstresult)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pluggy\\_callers.py\", line 121, in _multicall\n    res = hook_impl.function(*args)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\_pytest\\python.py\", line 157, in pytest_pyfunc_call\n    result = testfunction(**testargs)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pytest_asyncio\\plugin.py\", line 642, in inner\n    _loop.run_until_complete(task)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 641, in run_until_complete\n    self.run_forever()\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\windows_events.py\", line 321, in run_forever\n    super().run_forever()\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 608, in run_forever\n    self._run_once()\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1898, in _run_once\n    event_list = self._selector.select(timeout)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\windows_events.py\", line 444, in select\n    self._poll(timeout)\n  File \"C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\windows_events.py\", line 825, in _poll\n    status = _overlapped.GetQueuedCompletionStatus(self._iocp, ms)\n+++++++++++++++++++++++++++++++++++ Timeout +++++++++++++++++++++++++++++++++++\n",
      "stderr": "",
      "command": "C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pytest tests/performance/ -v --tb=short --timeout=30 --junit-xml=test-results-performance.xml -m performance",
      "timeout_limit": 30,
      "max_duration": 1200.0
    },
    "compliance": {
      "tier": "compliance",
      "success": false,
      "return_code": 1,
      "duration": 7.924544,
      "stdout": "============================= test session starts =============================\nplatform win32 -- Python 3.11.9, pytest-8.4.1, pluggy-1.6.0 -- C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\ncachedir: .pytest_cache\nmetadata: {'Python': '3.11.9', 'Platform': 'Windows-10-10.0.26100-SP0', 'Packages': {'pytest': '8.4.1', 'pluggy': '1.6.0'}, 'Plugins': {'anyio': '4.9.0', 'Faker': '37.5.3', 'asyncio': '1.1.0', 'cov': '6.2.1', 'forked': '1.6.0', 'json-report': '1.5.0', 'metadata': '3.1.1', 'mock': '3.14.1', 'split': '0.10.0', 'timeout': '2.4.0', 'xdist': '3.8.0'}}\nrootdir: C:\\Users\\fujif\\OneDrive\\Documents\\GitHub\\horme-pov\\src\\new_project\nconfigfile: pytest.ini\nplugins: anyio-4.9.0, Faker-37.5.3, asyncio-1.1.0, cov-6.2.1, forked-1.6.0, json-report-1.5.0, metadata-3.1.1, mock-3.14.1, split-0.10.0, timeout-2.4.0, xdist-3.8.0\nasyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function\ntimeout: 15.0s\ntimeout method: thread\ntimeout func_only: False\ncollecting ... collected 15 items\n\ntests/compliance/test_safety_compliance_framework.py::TestSafetyStandardsValidation::test_osha_compliance_validation PASSED [  6%]\ntests/compliance/test_safety_compliance_framework.py::TestSafetyStandardsValidation::test_ansi_compliance_validation PASSED [ 13%]\ntests/compliance/test_safety_compliance_framework.py::TestSafetyStandardsValidation::test_fall_protection_compliance PASSED [ 20%]\ntests/compliance/test_safety_compliance_framework.py::TestSafetyStandardsValidation::test_lockout_tagout_compliance FAILED [ 26%]\ntests/compliance/test_safety_compliance_framework.py::TestSkillLevelComplianceValidation::test_novice_user_restrictions FAILED [ 33%]\ntests/compliance/test_safety_compliance_framework.py::TestSkillLevelComplianceValidation::test_expert_user_access PASSED [ 40%]\ntests/compliance/test_safety_compliance_framework.py::TestSkillLevelComplianceValidation::test_skill_level_progression_validation PASSED [ 46%]\ntests/compliance/test_safety_compliance_framework.py::TestEnvironmentHazardValidation::test_construction_environment_hazards PASSED [ 53%]\ntests/compliance/test_safety_compliance_framework.py::TestEnvironmentHazardValidation::test_electrical_environment_hazards PASSED [ 60%]\ntests/compliance/test_safety_compliance_framework.py::TestEnvironmentHazardValidation::test_indoor_vs_outdoor_requirements PASSED [ 66%]\ntests/compliance/test_safety_compliance_framework.py::TestLegalAccuracyValidation::test_recommendation_legal_basis PASSED [ 73%]\ntests/compliance/test_safety_compliance_framework.py::TestLegalAccuracyValidation::test_critical_warning_identification FAILED [ 80%]\ntests/compliance/test_safety_compliance_framework.py::TestLegalAccuracyValidation::test_legal_standard_coverage PASSED [ 86%]\ntests/compliance/test_safety_compliance_framework.py::TestComplianceReporting::test_compliance_report_generation PASSED [ 93%]\ntests/compliance/test_safety_compliance_framework.py::TestComplianceReporting::test_audit_trail_generation PASSED [100%]\n\n================================== FAILURES ===================================\n________ TestSafetyStandardsValidation.test_lockout_tagout_compliance _________\ntests\\compliance\\test_safety_compliance_framework.py:573: in test_lockout_tagout_compliance\n    assert len(loto_requirements) > 0, \"Should have lockout/tagout requirements\"\nE   AssertionError: Should have lockout/tagout requirements\nE   assert 0 > 0\nE    +  where 0 = len([])\n______ TestSkillLevelComplianceValidation.test_novice_user_restrictions _______\ntests\\compliance\\test_safety_compliance_framework.py:595: in test_novice_user_restrictions\n    assert len(result.warnings) > 0, \"Novice users should receive safety warnings\"\nE   AssertionError: Novice users should receive safety warnings\nE   assert 0 > 0\nE    +  where 0 = len([])\nE    +    where [] = ComplianceValidationResult(product_code='PRD-00005', user_skill_level='novice', environment='workshop', compliance_status='compliant', applicable_requirements=[SafetyRequirement(requirement_id='ANSI-Z87-1-001', standard_id='ANSI-Z87.1', title='Eye Protection Required', description='Safety glasses or goggles required for impact hazards', compliance_level=<ComplianceLevel.MANDATORY: 'mandatory'>, risk_level=<RiskLevel.HIGH: 'high'>, applicable_environments=['workshop', 'construction', 'manufacturing', 'laboratory'], applicable_skill_levels=['all'], verification_method='Impact resistance testing', legal_reference='ANSI Z87.1-2020', enforcement_authority='ANSI'), SafetyRequirement(requirement_id='ANSI-B11-1-001', standard_id='ANSI-B11.1', title='Machine Guarding Required', description='Guards required for rotating machinery and cutting tools', compliance_level=<ComplianceLevel.MANDATORY: 'mandatory'>, risk_level=<RiskLevel.HIGH: 'high'>, applicable_environments=['manufacturing', 'workshop'], applicable_skill_levels=['all'], verification_method='Guard inspection and interlock testing', legal_reference='ANSI B11.1-2009', enforcement_authority='ANSI'), SafetyRequirement(requirement_id='...ll'], applicable_skill_levels=['all'], verification_method='Hazard assessment and PPE evaluation', legal_reference='29 CFR 1910.132', enforcement_authority='OSHA'), SafetyRequirement(requirement_id='ISO-45001-001', standard_id='ISO-45001', title='Occupational Health Management', description='Systematic approach to managing occupational health and safety', compliance_level=<ComplianceLevel.RECOMMENDED: 'recommended'>, risk_level=<RiskLevel.MEDIUM: 'medium'>, applicable_environments=['all'], applicable_skill_levels=['all'], verification_method='Management system audit', legal_reference='ISO 45001:2018', enforcement_authority='ISO')], violations=[], warnings=[], recommendations=['Required PPE: Eye Protection', 'Required PPE: Hearing Protection', 'Address machinery hazards as per applicable standards'], risk_assessment={'product_category': 'Power Tools', 'user_skill': 'novice', 'environment': 'workshop', 'base_risk_level': 'medium', 'applicable_standards': 4}, legal_notes=['ANSI-Z87.1: ANSI Z87.1-2020 - ANSI', 'ANSI-B11.1: ANSI B11.1-2009 - ANSI', 'OSHA-1910.132: 29 CFR 1910.132 - OSHA'], validation_timestamp=datetime.datetime(2025, 8, 4, 0, 27, 30, 859946), validator_version='1.0.0').warnings\n______ TestLegalAccuracyValidation.test_critical_warning_identification _______\ntests\\compliance\\test_safety_compliance_framework.py:800: in test_critical_warning_identification\n    assert len(high_risk_requirements) > 0, \\\nE   AssertionError: Should identify high-risk requirements for Power Tools/novice/electrical\nE   assert 0 > 0\nE    +  where 0 = len([])\n- generated xml file: C:\\Users\\fujif\\OneDrive\\Documents\\GitHub\\horme-pov\\src\\new_project\\test-results-compliance.xml -\n=========================== short test summary info ===========================\nFAILED tests/compliance/test_safety_compliance_framework.py::TestSafetyStandardsValidation::test_lockout_tagout_compliance\nFAILED tests/compliance/test_safety_compliance_framework.py::TestSkillLevelComplianceValidation::test_novice_user_restrictions\nFAILED tests/compliance/test_safety_compliance_framework.py::TestLegalAccuracyValidation::test_critical_warning_identification\n======================== 3 failed, 12 passed in 5.35s =========================\n",
      "stderr": "",
      "command": "C:\\Users\\fujif\\AppData\\Local\\Programs\\Python\\Python311\\python.exe -m pytest tests/compliance/ -v --tb=short --timeout=15 --junit-xml=test-results-compliance.xml -m compliance",
      "timeout_limit": 15,
      "max_duration": 600.0
    }
  }
}